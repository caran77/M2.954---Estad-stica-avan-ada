---
title: "a3"
author: "Carlos A. García"
date: "April 29, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Càrrega del fitxer

Establim el directori de feina
```{r directori de feina}
setwd("D:/Users/cagarcia/uoc/M2.954 - Estadística avançada/A3")
```

Llegim el fitxer proporcionat a la pràctica

```{r llegir el document}
satisfaccioLaboral <- read.csv2("rawData_clean1.csv", header = TRUE, sep = ",", dec = ".")
attach(satisfaccioLaboral)

summary(satisfaccioLaboral)
```
#Model de regressió lineal

##Model de regressió lineal múltiple (regressors quantitatius)

###Estimeu per mínims quadrats ordinaris un model lineal que expliqui la satisfacció laboral (happiness) d'un individu en funció de tres factors quantitatius: les hores treballades a la setmana (work_hours), l'edat (age), i els dies de baixa en el darrer any (sick_leave).

Com a primera aproximació, obtenim la matriu de correlacions.

```{r matriu de correlació}
cor(satisfaccioLaboral[,c("happiness", "work_hours", "age", "sick_leave")], use="complete")
```
Es pot veure que la major correlació se produeix amb la variable sick_leave.

```{r model de regressió lineal múltiple quantitatius}
lmFrame <- lm(formula = happiness ~ work_hours + age + sick_leave, data = satisfaccioLaboral)
summary(lmFrame)
```
###Avalueu la bondat d'ajust a través del coeficient de determinació (R2) i interpreteu-lo.
Com es pot veure $R^{2}$ és molt pobre (1 representa l'ajust perfecte, 0 cap ajust). Un ajust tan baix implica que la recta de regressió no és gaire bona.
```{r model de regressió lineal múltiple quantitatius R2}
summary(lmFrame)$r.squared
summary(lmFrame)$adj.r.squared
```
###A més, avalueu si algun dels regressos té influència significativa
Les tres variables tenen Pr(>|t|) < 5%, el que implica que les tres tenen una influència significativa.
```{r model de regressió lineal múltiple quantitatius pvalues}
summary(lmFrame)$coefficients[,4]
```
El signe és negatiu en el cas de les variables work_hours i sick_leave. Això vol dir que, com més creixen aquests dos valors, més baixa el nivell de happiness. El signe d'age és possitiu; augmenta el happiness a mida que creix l'age.
```{r model de regressió lineal múltiple quantitatius estimate}
summary(lmFrame)$coefficients[,1]
```
###Des del punt de vista de la qualitat del model de regressiu, podeu indicar una raó que justifiqui la no inclusió de seniority?
La correlació d'ambdues variables és molt elevada. Això implica que incloure seniority és afegir una variable redundant. Si existeix dependència entre les variables, direm
que hi ha multicol·linealitat.

Només com a nota, dir que el valor $R^{2}$ empitjora a mida que s'afegeixen variables.
```{r matriu de correlació seniority age}
cor(satisfaccioLaboral[,c("seniority", "age")], use="complete")
```
##Model de regressió lineal múltiple (regressors quantitatius i qualitatius)
###Estimeu per mínims quadrats ordinaris un model lineal que expliqui la satisfacció laboral (happiness) d'un individu en funció de cinc regressors.
```{r create dummy columns}
satisfaccioLaboral$sexR <- relevel(satisfaccioLaboral$sex, ref = "F")
satisfaccioLaboral$educ_levelR <- relevel(satisfaccioLaboral$educ_level, ref = "N")
```
###Un cop creades les noves variables, calculeu el model lineal usant la funció d'R lm
```{r dummy columns}
lmFrame <- lm(formula = happiness ~ work_hours + age + sick_leave + sexR 
              + educ_levelR, data = satisfaccioLaboral)
summary(lmFrame)
```
###Avalueu la bondat d'ajust a través del coeficient de determinació (R2) i compareu el resultat d'aquest model amb l'obtingut a l'apartat 1.1. Per a fer-ho, useu el coeficient R2 ajustat en la comparació. 
El coeficient R2 adjustat és lleugerament superior als obtinguts a l'apartat 1.1. Això vol dir que s'adjusta lleugerament millor, malgrat continúa sent un resultat pobre.
```{r r2 amb dummy columns}
summary(lmFrame)$r.squared
summary(lmFrame)$adj.r.squared
```
###Interpreteu també el significat dels coeficients obtinguts i la seva significació estadística. En particular, quina interpretació feu dels tres coeficients associats al factor educ_levelR?
Per una banda tenim els coeficients depenent de la variable:
```{r coeficients amb dummy columns}
summary(lmFrame)$coefficients[,1]
```
I per un altre, el p-value que ens indica la seva significació estadística (si és major de 5%, entenem que no és representativa)
```{r significat amb dummy columns}
summary(lmFrame)$coefficients[,4]

```
En el cas , particular de la satisfacció laboral en funció del nivell d'estudis:
\begin{enumerate}
\item Tant si els estudis són primaris com secundaris, el nivell de satisfacció és un 17\% inferior amb un nivell de significació proper al 3\%. Els treballadors amb estudis primaris o secundaris són més infeliços que els que no tenen estudis. El baix nivell de significació indica que és una dada representativa.
\item Si els estudis són universitaris, el nivell de satisfacció és un 80\% inferior amb un nivell de significació molt proper a 0. Els treballadors amb estudis universitaris són més feliços que els que no tenen estudis. El baix nivell de significació indica que és una dada representativa.
\end{enumerate}
##Realitzeu una predicció de la satisfacció laboral amb els dos models
Realitzeu la predicció del nivell de satifacció laboral d'una treballadora de 30 anys d'edat, amb 10 anys d'antiguitat a l'empresa, nivell educatiu de formació professional, que treballa 37 hores a la setmana i que va estar 7 dies de baixa l'any passat.
Al segon model no tenim en compte els anys d'experiència; calculat manualment tenim un happiness previst de:
```{r happiness lmframe 2}
ageVar <- 30
working_hoursVar <- 37
sick_daysVar <- 7
educ_leveVar <- "S"
sexVar <- "F"
happiness <- lmFrame$coefficients[1] + lmFrame$coefficients[7]+ 
  ageVar * lmFrame$coefficients[3] + 
  working_hoursVar * lmFrame$coefficients[2] + sick_daysVar * lmFrame$coefficients[4]
happiness
```
Al primer model no tenim en compte ni els anys d'experiència ni el sexe; calculat manualment tenim un happiness previst de:
```{r happiness lmframe 1}
lmFrame1 <- lm(formula = happiness ~ work_hours + age + sick_leave, data = satisfaccioLaboral)
happiness1 <- lmFrame1$coefficients[1] +  
  ageVar * lmFrame1$coefficients[3] + 
  working_hoursVar * lmFrame1$coefficients[2] + sick_daysVar * lmFrame1$coefficients[4]
happiness1
```
Realitzeu la predicció de la satisfacció laboral (happiness) i el càlcul de l'interval de confiança amb els dos models. Interpreteu els resultats.

Podem veure que els resultats són els mateixos que els realitzats amb els càlculs manuals. Calculem amb un interval de confiança del 95%:
```{r intervals de confiança}
newdata = data.frame(work_hours = working_hoursVar, age = ageVar, sick_leave = sick_daysVar)
predict.lm(lmFrame1, newdata, interval = "confidence", level = 0.95)
newdata = data.frame(work_hours = working_hoursVar, age = ageVar, sick_leave = sick_daysVar, 
                     sexR=sexVar, educ_levelR=educ_leveVar)
predict.lm(lmFrame, newdata, interval = "confidence", level = 0.95)
```
Com es pot veure, els valors i els intervals canvien depenent del model. El segon model incorpora el nivell d'educació, que és representativa. Tambè inclou el sexe, que no ho és. 

#Model de regressió logística

##Estimació d'un model de regressió logística

El primer pas serà crear una variable binària (low_happiness) que indiqui la condició de satisfacció baixa (low_happiness = 1) si happiness <= 4 o satisfacció normal/alta (low_happiness = 0) si happiness > 4.
```{r calcul low happiness}
satisfaccioLaboral$low_happiness <- ifelse(satisfaccioLaboral$happiness<=4, 1, 0)
```
###Calculeu el model de regressió logística on la variable dependent és "low_happiness" i les explicatives són work_hours, sexR i sick_leave
```{r regressió low happiness}
glmFrame <- glm(formula = low_happiness ~ work_hours + sexR + sick_leave, data = satisfaccioLaboral)
summary(glmFrame)
```
###Avalueu si algú dels regressores té influència significativa (p-valor del contrast individual inferior al 5%).

Sí. Les variables  work_hours i sick_leave tenen una influència significativa. El seu p-value és molt proper a 0.

###Avaluant els resultats, es pot dir que un individu amb moltes hores de treball té major probabilitat de tenir "low.happiness"?

Sí, ja que el coeficient és positiu (en aquest cas, 1 és low.happiness; més elevat significa "més trist") i la variable té una influència significativa.

###Es pot afirmar a partir del model que ser dona augmenta la probabilitat de tenir "low.happiness"?

No. Sí que a primera vista ho sembla (el coefient de home és negatiu, el que vol dir menys infelicitat). No ho podem afrimar perque la variable no té una influència significativa.

##Predicció en el model lineal generalizat (model de regressió logística)

###Usant el model anterior, calculeu la probabilitat de tenir un baix happiness (low_happiness) per a un home que treballa 40 hores a la setmana i va estar 15 dies de baixa l'any passat.
Podem veure que fent els càlculs, tant de forma automàtica (funció predict.glm) com manual, el resultat és el mateix (proper a 1).
```{r regressió log predict man}
working_hoursVar <- 40
sick_daysVar <- 15
sexVar <- "M"
glmFrame$coefficients
happiness <- glmFrame$coefficients[1] + glmFrame$coefficients[3] +
  working_hoursVar * glmFrame$coefficients[2] + sick_daysVar * glmFrame$coefficients[4]
happiness
newdata = data.frame(work_hours = working_hoursVar, sexR = sexVar, sick_leave = sick_daysVar)
predict.glm(glmFrame, newdata)
```
##Millora del model
##Decidiu si es prefereix el model inicial o bé un dels models amb cityR, amb educ_levelR, o amb les dues.
Primer obtenim les diferentes línees logaritmíques de regressió. Concretament:

\begin{enumerate}
\item Incloent la ciutat, prenent com a referència Barcelona (frame glmFrameCity)
\item Incloent el nivell d'estudis, prenent com a referència els estudis bàsics (frame glmFrameEduc)
\item Incloent les ambdues anteriors (frame glmFrameCityEduc)
\end{enumerate}

```{r regressió log city study}
cityVar = "Barcelona"
satisfaccioLaboral$cityR <- relevel(satisfaccioLaboral$city, ref = cityVar)
glmFrameCity <- glm(formula = low_happiness ~ work_hours + sexR + sick_leave + cityR, 
                    data = satisfaccioLaboral)
summary(glmFrameCity)
glmFrameEduc <- glm(formula = low_happiness ~ work_hours + sexR + sick_leave + educ_levelR, 
                    data = satisfaccioLaboral)
summary(glmFrameEduc)
glmFrameCityEduc <- glm(formula = low_happiness ~ work_hours + sexR + sick_leave + educ_levelR + cityR, 
                    data = satisfaccioLaboral)
summary(glmFrameCityEduc)
```
Com es pot veure, el menor AIC és el del model que inclou ciutat i nivell d'estudis:
```{r regressió AIC}
AIC(glmFrameCity)
AIC(glmFrameEduc)
AIC(glmFrameCityEduc)
```
Crida molt l'atenció com creix el nivell de lowHappiness si la persona fa feina a Santiago de Compostela. A més, el valor és representatiu, ja que el nivell de p-value és molt proper a 0.
Com a nota, dir que AIC$\footnote[1]{\url{https://en.wikipedia.org/wiki/Akaike_information_criterion}}$ és l'acrònim de "Akaike information criterion". És un estimador relatiu de la quallitat d'un model estadístic per a un conjunt de dades.
Dir que es correspon amb:
$$ AIC = 2k - 2ln(L)$$
On k és el nombre de variables i L és el màxim valor de la funció de verosimilitut per al model estimat
##Qualitat de l'ajust
###Calculeu la matriu de confusió del millor model de l'apartat 2.3 suposant un llindar de discriminació del 75%

Obtenim la matriu de confusió on mostram les variables:
\begin{enumerate}
\item falsePositive. Nombre de falsos positius; el nivell real de low\_happiness és 1, però obtenim una probalitat menor del 75\% de que així sigui segons la recta de regressió.
\item okPredictPositive. Nombre de positius que es preveuen com a positius; el nivell real de low\_happiness és 1 i obtenim una probalitat igual o superior al 75\% de que així sigui segons la recta de regressió. La previsió segons la recta de regressió és correcta.
\item okPredictNegative. Nombre de negatius que es preveuen com a negatius; el nivell real de low\_happiness és 0 i obtenim una probalitat inferior al 75\% de que així sigui segons la recta de regressió. La previsió segons la recta de regressió és correcta.
\item falseNegative. Nombre de falsos negatius; el nivell real de low\_happiness és 0, però obtenim una probalitat igual o superior al 75\% de que el low\_happiness sigui 1 segons la recta de regressió.
\end{enumerate}

```{r confusion matrix}
satisfaccioLaboral$low_happiness_predict <- predict(glmFrameCityEduc)

pThreshold <- 0.75
falsePositive <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict >= pThreshold 
  & satisfaccioLaboral$low_happiness == 0])
okPredictPositive <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict >= pThreshold 
  & satisfaccioLaboral$low_happiness == 1])
okPredictNegative <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict < pThreshold 
  & satisfaccioLaboral$low_happiness == 0])
falseNegative <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict < pThreshold 
  & satisfaccioLaboral$low_happiness == 1])
falsePositive
okPredictPositive
okPredictNegative
falseNegative
```
El percentatge de valors correctament classificats és:
```{r ok classified}
okClassified <- (okPredictPositive + okPredictNegative)/(nrow(satisfaccioLaboral))
okClassified
```
El percentatge de valors classificats erròniament és:
```{r ko classified}
koClassified <- (falsePositive + falseNegative)/(nrow(satisfaccioLaboral))
koClassified
```
##Corba ROC

###Realitzeu el dibuix de les corbes ROC per a representar la qualitat dels models predictius obtinguts a l'apartat 2.3 en un únic gràfic
```{r ROC}
par(pty = "s")
rocCityEduc <- pROC::roc(satisfaccioLaboral$low_happiness, glmFrameCityEduc$fitted.values, plot=TRUE, percent=TRUE,
          legacy.axes=TRUE, lwd=1, col="#3737ff",
          xlab="False positive percentage", ylab="True positive percentage", add=FALSE, print.auc.y=40)
rocCity <- pROC::roc(satisfaccioLaboral$low_happiness, glmFrameCity$fitted.values, plot=TRUE, percent=TRUE,
          legacy.axes=TRUE, lwd=1, col="#ff3737",
          xlab="False positive percentage", ylab="True positive percentage", add=TRUE, print.auc.y=40)
rocEduc <- pROC::roc(satisfaccioLaboral$low_happiness, glmFrameEduc$fitted.values, plot=TRUE, percent=TRUE,
          legacy.axes=TRUE, lwd=1, col="#37ff37",
          xlab="False positive percentage", ylab="True positive percentage", add=TRUE, print.auc.y=40)
```
Imprimim els gràfics en percentatge per a veure-ho millor. La recta diagonal representa el cas en el que la proporció d'elements bé classificats és igual al percentatge d'elements mal classificats. És a dir: com més allunyada estigui la corva ROC de la recta, major és el percentatge d'elements bé classificats. Es veu clarament que el millor classificador és el que inclou la ciutat i el nivell educatiu (corba blava). Els altres dos classificadors són molt similars.
El valor AUC se correspon amb l'àrea sota la corba. Com major sigui aquesta àrea, més allunyada està la corba i millor és el classificador. Podem veure que es confirma que el millor classificador és el que inclou la ciutat i el nivell d'educació.
```{r AUC}
pROC::auc(rocCityEduc)
pROC::auc(rocCity)
pROC::auc(rocEduc)
```
Podem veure que la corva blava s'allunya més de la recta sobre el 55%. Així, sembla que se classificaran millor més elements si prenem aquest límit. Fent la prova:
```{r confusion matrix 55}
pThreshold <- 0.55
falsePositive <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict >= pThreshold 
  & satisfaccioLaboral$low_happiness == 0])
okPredictPositive <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict >= pThreshold 
  & satisfaccioLaboral$low_happiness == 1])
okPredictNegative <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict < pThreshold 
  & satisfaccioLaboral$low_happiness == 0])
falseNegative <- length(satisfaccioLaboral$low_happiness_predict[
  satisfaccioLaboral$low_happiness_predict < pThreshold 
  & satisfaccioLaboral$low_happiness == 1])
falsePositive
okPredictPositive
okPredictNegative
falseNegative
okClassified <- (okPredictPositive + okPredictNegative)/(nrow(satisfaccioLaboral))
okClassified
koClassified <- (falsePositive + falseNegative)/(nrow(satisfaccioLaboral))
koClassified
```
Podem veure que, efectivament, el percentatge és clarament millor. 